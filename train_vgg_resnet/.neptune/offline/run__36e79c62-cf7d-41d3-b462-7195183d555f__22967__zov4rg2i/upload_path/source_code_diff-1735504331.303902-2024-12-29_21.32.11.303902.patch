diff --git a/config.py b/config.py
index 4d57c49..e7c5c66 100644
--- a/config.py
+++ b/config.py
@@ -1,9 +1,8 @@
 import os
 
-path_preds = os.getenv('PATH_ZEUS')
-path_preds = '/pasteur/zeus/projets/p02/bia/ahabis/CAMELYON/'
-path_slide_tumor_train = os.path.join(path_preds, "train/tumor")
-path_slide_tumor_test = os.path.join(path_preds, "test/tumor")
+path_preds = "/Users/erwan/Data/Dofus"
+path_slide_tumor_train = os.path.join(path_preds, "train")
+path_slide_tumor_test = os.path.join(path_preds, "test")
 path_annotations_train = os.path.join(path_preds, "train/annotations")
 path_annotations_test = os.path.join(path_preds, "test/annotations")
 path_dataframe_train = os.path.join(path_preds, "dataframe_train.csv")
@@ -19,18 +18,19 @@ path_heatmaps = os.path.join(path_preds, "heatmaps")
 path_segmaps = os.path.join(path_preds, "segmaps")
 path_metric_tables = os.path.join(path_preds, "metric_tables")
 path_weights = os.path.join(path_preds, "weights")
-path_prediction_patches = os.path.join(path_preds, 'patches_prediction')
-path_prediction_patches_correction = os.path.join(path_preds, 'patches_prediction_correction')
-path_uncertainty_patches = os.path.join(path_preds, 'patches_uncertainty')
-
+path_prediction_patches = os.path.join(path_preds, "patches_prediction")
+path_prediction_patches_correction = os.path.join(
+    path_preds, "patches_prediction_correction"
+)
+path_uncertainty_patches = os.path.join(path_preds, "patches_uncertainty")
 
 
 optimal_threshold = 0.6
 percentage_scribbled_regions = 0.1
-ov = 0.7 #### overlap
-ps = 512 #### patch_size
-bs = 16 #### batch_size
-n_passes = 20 ## monte_carlo predictions
+ov = 0.7  #### overlap
+ps = 128  #### patch_size
+bs = 16  #### batch_size
+n_passes = 20  ## monte_carlo predictions
 
 test_set = [
     "test_040",
@@ -56,7 +56,8 @@ test_set = [
     "test_116",
     "test_117",
     "test_010",
-    "test_011"]
+    "test_011",
+]
 
 
 val_set = [
@@ -84,4 +85,4 @@ val_set = [
     "test_099",
     "test_038",
     "test_013",
-]
\ No newline at end of file
+]
diff --git a/scribble_generation/create_dataframe_scribbles.py b/scribble_generation/create_dataframe_scribbles.py
index 945e920..96cbf59 100644
--- a/scribble_generation/create_dataframe_scribbles.py
+++ b/scribble_generation/create_dataframe_scribbles.py
@@ -44,7 +44,7 @@ else:
 
 dic = {}
 
-
+print("hey")
 for i, filename in enumerate(tqdm(os.listdir(path_slide))):
     ### Go through all the slides to create healthy and tumor scribbles
 
@@ -53,50 +53,74 @@ for i, filename in enumerate(tqdm(os.listdir(path_slide))):
         annotations_tumor,
         scribbles_tumor,
         annotation_healthy,
-        scribble_healthy,
-    ) = get_scribbles_and_annotations(path_image, split)
-    dic[filename] = [scribbles_tumor, scribble_healthy, annotations_tumor]
+        scribbles_healthy,
+    ) = get_scribbles_and_annotations_manually(path_image, split)
+    dic[filename] = [scribbles_tumor, scribbles_healthy, annotations_tumor]
 
     ###### SELECT percentage_scribbled_regions% of tumor regions ######
     ###### Remove scribble Healthy on tumor regions ######
 
-    if dic[filename][1] is not None:
-        n = dic[filename][1].shape[0]
-        bool_filename = np.ones(n)
-        n_tumor = len(dic[filename][0])
-        areas = np.zeros(n_tumor)
+    # if dic[filename][1] is not None:
+    #     n = dic[filename][1].shape[0]
+    #     bool_filename = np.ones(n)
+    #     n_tumor = len(dic[filename][0])
+    #     areas = np.zeros(n_tumor)
 
-        for i in range(n):
-            point = Point(dic[filename][1][i])
-            for j, polygon in enumerate(dic[filename][2]):
-                poly = Polygon(np.squeeze(polygon))
-                if i == 0:
-                    areas[j] = poly.area
-                if poly.contains(point):
-                    bool_filename[i] = 0
-                    break
-        dic[filename][1] = dic[filename][1][bool_filename.astype(bool)]
+    #     for i in range(n):
+    #         point = Point(dic[filename][1][i])
+    #         for j, polygon in enumerate(dic[filename][2]):
+    #             poly = Polygon(np.squeeze(polygon))
+    #             if i == 0:
+    #                 areas[j] = poly.area
+    #             if poly.contains(point):
+    #                 bool_filename[i] = 0
+    #                 break
+    #     dic[filename][1] = dic[filename][1][bool_filename.astype(bool)]
 
-        args = np.flip(np.argsort(areas))[: int(percentage_scribbled_regions * n_tumor)]
-        dic[filename][0] = [dic[filename][0][u] for u in args]
+    #     args = np.flip(np.argsort(areas))[: int(percentage_scribbled_regions * n_tumor)]
+    #     dic[filename][0] = [dic[filename][0][u] for u in args]
 
 
 df = pd.DataFrame(columns=["wsi", "point", "class"])
 
 for filename in tqdm(dic.keys()):
     scribble_tumor, scribble_healthy, _ = dic[filename]
-    scribble_tumor = np.squeeze(np.concatenate(scribble_tumor))
+    # scribble_tumor = np.squeeze(np.concatenate(scribble_tumor))
+    # scribble_healthy = np.squeeze(np.concatenate(scribble_healthy))
+
+    if scribble_tumor is not None:
+        # scribble_tumor = np.squeeze(np.concatenate(scribble_tumor))
+
+        for i in range(scribble_tumor.shape[0]):
+            df = pd.concat(
+                [
+                    df,
+                    pd.DataFrame(
+                        [{"wsi": filename, "point": scribble_tumor[i], "class": 1}]
+                    ),
+                ],
+                ignore_index=True,
+            )
 
-    for i in range(scribble_tumor.shape[0]):
-        df = df.append(
-            {"wsi": filename, "point": scribble_tumor[i], "class": 1}, ignore_index=True
-        )
+        # df = df.append(
+        #     {"wsi": filename, "point": scribble_tumor[i], "class": 1}, ignore_index=True
+        # )
     if scribble_healthy is not None:
+        # scribble_healthy = np.squeeze(np.concatenate(scribble_healthy))
         for i in range(scribble_healthy.shape[0]):
-            df = df.append(
-                {"wsi": filename, "point": scribble_healthy[i], "class": 0},
+            df = pd.concat(
+                [
+                    df,
+                    pd.DataFrame(
+                        [{"wsi": filename, "point": scribble_healthy[i], "class": 0}]
+                    ),
+                ],
                 ignore_index=True,
             )
-if not os.path.exists(path_dataframe):
-    os.makedirs(path_dataframe)
+            # df = df.append(
+            #     {"wsi": filename, "point": scribble_healthy[i], "class": 0},
+            #     ignore_index=True,
+            # )
+# if not os.path.exists(path_dataframe):
+#     os.makedirs(path_dataframe)
 df.to_csv(path_dataframe)
diff --git a/scribble_generation/dataframe_to_images.py b/scribble_generation/dataframe_to_images.py
index 25b617e..f8a0b96 100644
--- a/scribble_generation/dataframe_to_images.py
+++ b/scribble_generation/dataframe_to_images.py
@@ -8,10 +8,12 @@ from multiprocessing import Pool
 import ast
 import pandas as pd
 import numpy as np
-from openslide import OpenSlide
+
+# from openslide import OpenSlide
 from tqdm import tqdm
+import matplotlib.pyplot as plt
 
-ImageFile.LOAD_TRUNCATED_IMAGES = True
+# ImageFile.LOAD_TRUNCATED_IMAGES = True
 import argparse
 
 parser = argparse.ArgumentParser(description="Code to generate patches from scribbles.")
@@ -28,14 +30,14 @@ if split == "train":
     path_patches = path_patches_scribbles_train
     path_images = path_slide_tumor_train
     path_dataframe = path_dataframe_train
-    dataframe = pd.read_csv(path_dataframe_train, index_col = 0)    
+    dataframe = pd.read_csv(path_dataframe_train, index_col=0)
 
 else:
     path_patches = path_patches_scribbles_test
     path_images = path_slide_tumor_test
     path_dataframe = path_dataframe_test
-    dataframe = pd.read_csv(path_dataframe, index_col = 0)
-    
+    dataframe = pd.read_csv(path_dataframe, index_col=0)
+
 
 if not os.path.exists(path_patches):
     os.makedirs(path_patches)
@@ -49,8 +51,8 @@ slides = list(np.unique(np.array(list(dataframe["wsi"]))))
 def df_to_images(filename):
     dataframe_subset = dataframe[dataframe["wsi"] == filename]
     dataframe_subset = dataframe_subset.reset_index(drop=True)
-    path = os.path.join(path_images, filename)
-    img = OpenSlide(path)
+    # path = os.path.join(path_images, filename)
+    img = plt.imread(os.path.join(path_images, filename))
 
     for idx in tqdm(range(dataframe_subset.shape[0])):
         filename, point, y = dataframe_subset.loc[idx]
@@ -58,23 +60,43 @@ def df_to_images(filename):
         point = " ".join(point.split())
         point = point.replace("[ ", "[")
         point = point.replace(" ", ",")
-        point = tuple(np.array(ast.literal_eval(point)).astype(int) - ps // 2)
-        region = img.read_region(point, level=0, size=(ps, ps))
-        region = region.convert("RGB")
-        region.save(
+        point = tuple(np.array(ast.literal_eval(point)).astype(int))
+        # # region = img.read_region(point, level=0, size=(ps, ps))
+        # region = region.convert("RGB")
+
+        center = point[::-1]  # Example: center at (100, 150)
+
+        # Calculate the top-left corner of the patch
+        top_left = (
+            center[0] - min(center[0], ps // 2),
+            center[1] - min(center[1], ps // 2),
+        )
+
+        # Calculate the bottom-right corner of the patch
+        bottom_right = (
+            min(center[0] + ps // 2, img.shape[0] - 1),
+            min(center[1] + ps // 2, img.shape[1] - 1),
+        )
+
+        # Extract the patch from the image
+        patch = img[top_left[0] : bottom_right[0], top_left[1] : bottom_right[1]]
+
+        patch = np.pad(
+            patch, ((ps - patch.shape[0], 0), (ps - patch.shape[1], 0), (0, 0))
+        )
+
+        plt.imsave(
             os.path.join(
                 path_patches,
-                "image_"
-                + str(idx)
-                + "_"
-                + filename.split("_")[1]
-                + "_"
-                + str(y)
-                + ".png",
-            )
+                "image_" + str(idx) + "_" + filename + "_" + str(y) + ".png",
+            ),
+            patch,
         )
 
 
 if __name__ == "__main__":
-    pool = Pool(processes=32)
-    pool.map(df_to_images, slides)
+    # pool = Pool(processes=16)
+    # pool.map(df_to_images, slides)
+
+    for slide in tqdm(slides):
+        df_to_images(slide)
diff --git a/scribble_generation/scribble_inside_shape.py b/scribble_generation/scribble_inside_shape.py
index a60148c..ac35684 100644
--- a/scribble_generation/scribble_inside_shape.py
+++ b/scribble_generation/scribble_inside_shape.py
@@ -4,7 +4,6 @@ from pathlib import Path
 sys.path.append(str(Path(__file__).resolve().parent.parent))
 import xml.etree.ElementTree as ET
 import networkx as nx
-import geopandas as gpd
 from shapely.geometry import Polygon
 from shapely.ops import triangulate
 import random
@@ -21,14 +20,11 @@ warnings.filterwarnings("ignore")
 
 
 class Scribble:
-    def __init__(
-        self, filename, percent, split, show=False
-    ):
+    def __init__(self, filename, percent, split, show=False):
         self.split = split
         self.filename = filename
         self.percent = percent
         self.show = show
-        self.path_camelyon = path_camelyon
 
         if self.split == "train":
             self.path_annotations = path_annotations_train
@@ -129,7 +125,7 @@ class Scribble:
                 for u in range(polygon.shape[0]):
                     x, y = polygon.loc[u]["geometry"].exterior.xy
                     axs.fill(x, y, alpha=0.5, color=np.random.randint(0, 255, 3) / 255)
-                plt.axis('off')
+                plt.axis("off")
                 plt.show()
             return polygon
         else:
@@ -206,12 +202,11 @@ class Scribble:
         distance = np.insert(distance, 0, 0) / distance[-1]
         # Interpolation for different methods:
         alpha = np.linspace(0, 1, nb_)
-        interpolator = CubicSpline(distance, coordinates) 
+        interpolator = CubicSpline(distance, coordinates)
         interpolated_points = interpolator(alpha)
         return interpolated_points, contour
 
     def scribble(self, annotation, ps=ps, ov=0.8):
-        
         """
         Input: the annotation of the healthy or tumor region
 
@@ -264,10 +259,23 @@ class Scribble:
         )
         arr = interpolated_points
         nb = arr.shape[0]
-        remove = int((nb * self.percent)/2)
+        remove = int((nb * self.percent) / 2)
         scribble = arr[remove : nb - remove, :]
         length = np.sum(np.sqrt(np.sum((arr[:-1] - arr[1:]) ** 2, axis=1)))
         nb_patches = int(length / (ps * (1 - ov))) + 1
         indices = np.linspace(1, scribble.shape[0], nb_patches).astype(int) - 1
         arr = scribble[indices]
         return arr, contour, scribble, coordinates
+
+    def manual_scribble(self, interpolated_points, ps=ps, ov=0.8):
+        if interpolated_points.shape[0] > 0:
+            arr = interpolated_points
+            nb = arr.shape[0]
+            remove = int((nb * self.percent) / 2)
+            scribble = arr[remove : nb - remove, :]
+            length = np.sum(np.sqrt(np.sum((arr[:-1] - arr[1:]) ** 2, axis=1)))
+            nb_patches = int(length / (ps * (1 - ov))) + 1
+            indices = np.linspace(1, scribble.shape[0], nb_patches).astype(int) - 1
+            arr = scribble[indices]
+
+            return scribble
diff --git a/scribble_generation/utils.py b/scribble_generation/utils.py
index b61b6b3..98c0837 100644
--- a/scribble_generation/utils.py
+++ b/scribble_generation/utils.py
@@ -4,32 +4,134 @@ from pathlib import Path
 sys.path.append(str(Path(__file__).resolve().parent.parent))
 from config import *
 from scribble_inside_shape import Scribble
-from histolab.slide import Slide
-from histolab.masks import TissueMask
-from histolab.filters.image_filters import (
-    ApplyMaskImage,
-    GreenPenFilter,
-    Invert,
-    OtsuThreshold,
-    RgbToGrayscale,
-)
-from histolab.filters.morphological_filters import RemoveSmallHoles, RemoveSmallObjects
+
 import numpy as np
-import cv2
 from tqdm import tqdm
 
+import matplotlib.pyplot as plt
+
+
+def get_scribbles_and_annotations_manually(filename, split):
+
+    print("la")
+
+    if split == "train":
+        path_image = path_slide_tumor_train
+    else:
+        path_image = path_slide_tumor_test
+
+    ### First extract the largest tissue component on the slide
+    # to generate a healthy scribble later
+
+    image = plt.imread(os.path.join(path_image, filename))
+
+    # s = Scribble(filename, percent=0.0, split=split)
+
+    # Draw tumor
+
+    coords = []
+
+    # fig, ax = plt.subplots()
+
+    # ax.imshow(image)
+
+    def on_click(event):
+        # Check if the click is inside the plot area
+        if event.inaxes is not None:
+            # Get the x and y data from the event
+            x, y = event.xdata, event.ydata
+            # Print the coordinates of the clicked point
+            print(f"Clicked at: x = {x}, y = {y}")
+            coords.append([np.floor(x), np.floor(y)])
+
+    # Create a plot
+    fig, ax = plt.subplots()
+
+    # Add a simple plot for reference
+    ax.imshow(image)
+    # Connect the click event to the on_click function
+    fig.canvas.mpl_connect("button_press_event", on_click)
+
+    # Show the plot
+    plt.legend()
+    plt.show()
+
+    # print(np.array(coords))
+
+    if len(coords) > 0:
+
+        scribbles_tumor = np.array(coords)
+    else:
+        scribbles_tumor = None
+
+    # Draw healthy
+
+    coords = []
+
+    # fig, ax = plt.subplots()
+
+    # ax.imshow(image)
+
+    def on_click(event):
+        # Check if the click is inside the plot area
+        if event.inaxes is not None:
+            # Get the x and y data from the event
+            x, y = event.xdata, event.ydata
+            # Print the coordinates of the clicked point
+            print(f"Clicked at: x = {x}, y = {y}")
+            coords.append([np.floor(x), np.floor(y)])
+
+    # Create a plot
+    fig, ax = plt.subplots()
+
+    # Add a simple plot for reference
+    ax.imshow(image)
+    # Connect the click event to the on_click function
+    fig.canvas.mpl_connect("button_press_event", on_click)
+
+    # Show the plot
+    plt.legend()
+    plt.show()
+
+    print(np.array(coords))
+
+    # scribbles_healthy = s.manual_scribble(np.array(coords))
+
+    if len(coords) > 0:
+
+        scribbles_healthy = np.array(coords)
+    else:
+        scribbles_healthy = None
+
+    return (None, scribbles_tumor, None, scribbles_healthy)
+
+
+class LineDrawer(object):
+    lines = []
+
+    def draw_line(self):
+        ax = plt.gca()
+        xy = plt.ginput(2)
+
+        x = [p[0] for p in xy]
+        y = [p[1] for p in xy]
+        line = plt.plot(x, y)
+        ax.figure.canvas.draw()
+
+        self.lines.append(line)
+
 
 def get_scribbles_and_annotations(filename, split):
 
-    if split == 'train':
+    if split == "train":
         path_image = path_slide_tumor_train
-    else: 
+    else:
         path_image = path_slide_tumor_test
-    
-    ### First extract the largest tissue component on the slide 
-    #to generate a healthy scribble later
 
-    slide = Slide(os.path.join(path_image,filename), processed_path="")
+    ### First extract the largest tissue component on the slide
+    # to generate a healthy scribble later
+
+    slide = Slide(os.path.join(path_image, filename), processed_path="")
 
     mask = TissueMask(
         RgbToGrayscale(),
@@ -66,9 +168,9 @@ def get_scribbles_and_annotations(filename, split):
         annotation_contour = dataframe_annotation[annotation_id]
         annotation_contour = annotation_contour[~annotation_contour.isnull()]
         contour_tissue = np.vstack(annotation_contour.to_numpy())
-        try :
+        try:
             scribble_tumor, annotation, _, _ = s.scribble(contour_tissue)
-        except: 
+        except:
             scribble_tumor = None
         if scribble_tumor is not (None):
             scribble_tumor = scribble_tumor
@@ -80,6 +182,6 @@ def get_scribbles_and_annotations(filename, split):
     ### Generate a scribble in a healthy region
     try:
         scribble_healthy, _, _, _ = s.scribble(annotation_healthy.squeeze())
-    except: 
+    except:
         scribble_healthy = None
     return (annotations_tumor, scribbles_tumor, annotation_healthy, scribble_healthy)
diff --git a/train_vgg_resnet/generator.py b/train_vgg_resnet/generator.py
index 4e1ec82..878b937 100644
--- a/train_vgg_resnet/generator.py
+++ b/train_vgg_resnet/generator.py
@@ -53,12 +53,8 @@ dataset_test = CustomImageDataset(
     path_image=path_patches_scribbles_test, augmenter_bool=True
 )
 
-loader_train = DataLoader(
-    batch_size=bs, dataset=dataset_train, num_workers=32, shuffle=True
-)
+loader_train = DataLoader(batch_size=bs, dataset=dataset_train, shuffle=True)
 
-loader_test = DataLoader(
-    batch_size=bs, dataset=dataset_test, num_workers=32, shuffle=False
-)
+loader_test = DataLoader(batch_size=bs, dataset=dataset_test, shuffle=False)
 
 dataloaders = {"train": loader_train, "test": loader_test}
diff --git a/train_vgg_resnet/train.py b/train_vgg_resnet/train.py
index 2f49201..06871d9 100644
--- a/train_vgg_resnet/train.py
+++ b/train_vgg_resnet/train.py
@@ -11,10 +11,15 @@ import torch
 from models import *
 import neptune
 import argparse
+from tqdm import tqdm
 
 normalize = Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
-prec = BinaryPrecision().cuda()
-rec = BinaryRecall().cuda()
+
+device = device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
+
+
+prec = BinaryPrecision().to(device)
+rec = BinaryRecall().to(device)
 
 
 parser = argparse.ArgumentParser(
@@ -30,9 +35,9 @@ args = parser.parse_args()
 name_model = args.model
 
 if name_model == "vgg":
-    model = VGG16(vgg16(pretrained=True)).cuda()
+    model = VGG16(vgg16(pretrained=True)).to(device)
 else:
-    model = RESNET50(resnet50(pretrained=True)).cuda()
+    model = RESNET50(resnet50(pretrained=True)).to(device)
 
 optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
 scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)
@@ -40,23 +45,27 @@ loss = torch.nn.BCELoss(reduction="mean")
 
 run = neptune.init_run(
     mode="offline",
-    project=os.environ["NEPTUNE_WORKSPACE"],
-    api_token=os.environ["NEPTUNE_API_TOKEN"],
+    project="erwandereure/Dofus-bot",
+    api_token="eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmNGVlOGIyNS03ZTE5LTQ5YzctYjBlZS01MDQxMGM1YmY4ZTcifQ==",
 )
 run["config/optimizer"] = "Adam"
 
 
 def train(model, optimizer, train_dl, val_dl, epochs=100, loss=loss):
-    tmp = (torch.ones(1) * 1e15).cuda()
-    for epoch in range(1, epochs + 1):
+    tmp = (torch.ones(1) * 1e15).to(device)
+    print("ici la ")
+    for epoch in tqdm(range(1, epochs + 1)):
         # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------
         model.train()
-        model.cuda()
+        model.to(device)
         loss_tot = 0.0
+
+        print("dqsdqs")
         for batch in train_dl:
             optimizer.zero_grad()
-            images = normalize(batch[0].float().cuda())
-            ys = torch.unsqueeze(batch[1], dim=-1).float().cuda()
+            images = normalize(batch[0].float().to(device))
+            ys = torch.unsqueeze(batch[1], dim=-1).float().to(device)
+            print("avant modele")
             pred_ys = model(images)
             loss_ = loss(pred_ys, ys)
             pred_ys = torch.flatten(pred_ys)
@@ -77,12 +86,12 @@ def train(model, optimizer, train_dl, val_dl, epochs=100, loss=loss):
         num_val_correct = 0
         num_val_examples = 0
 
-        mean = torch.zeros(1).cuda()
+        mean = torch.zeros(1).to(device)
         with torch.no_grad():
             for batch in val_dl:
                 optimizer.zero_grad()
-                images = normalize(batch[0].float().cuda())
-                ys = torch.unsqueeze(batch[1], dim=-1).float().cuda()
+                images = normalize(batch[0].float().to(device))
+                ys = torch.unsqueeze(batch[1], dim=-1).float().to(device)
 
                 pred_ys = model(images)
                 val_loss = loss(pred_ys, ys)
@@ -113,11 +122,12 @@ def train(model, optimizer, train_dl, val_dl, epochs=100, loss=loss):
                 )
     return 0
 
+
 train(
     model,
     optimizer,
     dataloaders["train"],
     dataloaders["test"],
-    epochs=40,
+    epochs=2,
     loss=loss,
 )
