{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eed98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from generator_predict import *\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e359d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '/home/ahabis/sshfs/CAMELYON/test/images/'\n",
    "path_annotations='/home/ahabis/sshfs/CAMELYON/test/annotations/'\n",
    "path_masks = 'true_masks/'\n",
    "path_patches = 'patches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0113fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_dropout(model):\n",
    "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
    "    for m in model.modules():\n",
    "        if m.__class__.__name__.startswith('Dropout'):\n",
    "            m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990088c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(pretrained=True)\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self,model):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.resnet = model\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc1 = torch.nn.Linear(1000,1000)\n",
    "        self.fc2 = torch.nn.Linear(1000,1000)\n",
    "        self.fc3 = torch.nn.Linear(1000,1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.drop = torch.nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_features = self.resnet(x)\n",
    "        return x_features\n",
    "\n",
    "model = ResNet(model)\n",
    "model.load_state_dict(torch.load('weights1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eab69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monte_carlo_model(torch.nn.Module):\n",
    "    def __init__(self, model, n_passes = 20): \n",
    "        super(Monte_carlo_model, self).__init__()\n",
    "        \n",
    "        self.model = model\n",
    "        self.n_passes = n_passes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_features = self.model(x)\n",
    "        predictions  = []\n",
    "        \n",
    "        for i in range(self.n_passes):\n",
    "            \n",
    "            pred = self.model.fc1(x_features)\n",
    "            pred = self.model.relu(pred)\n",
    "            pred = self.model.drop(pred)\n",
    "            \n",
    "            pred = self.model.fc2(pred)\n",
    "            pred = self.model.relu(pred)\n",
    "            pred = self.model.drop(pred)\n",
    "            \n",
    "            pred = self.model.fc3(pred)\n",
    "            pred = self.model.sigmoid(pred) \n",
    "\n",
    "            predictions.append(pred)\n",
    "        predictions = torch.stack(predictions)\n",
    "        return x_features, predictions\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = Monte_carlo_model(model = model,\n",
    "                             n_passes = 20)\n",
    "mc_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abfc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_dl):\n",
    "    # --- EVALUATE ON VALIDATION SET -------------------------------------\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    enable_dropout(model)\n",
    "    \n",
    "    all_labels = []\n",
    "    all_predicted_labels = []\n",
    "    all_features = []\n",
    "    mean = torch.zeros(1).cuda()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_dl):\n",
    "            images    = batch[0].float().cuda()\n",
    "            ys    = batch[1].float().cpu().detach().numpy()           \n",
    "            out = model(images)\n",
    "            pred_ys = out[1].cpu().detach().numpy()\n",
    "            features = out[0].cpu().detach().numpy()\n",
    "            all_labels.append(ys)\n",
    "            all_predicted_labels.append(pred_ys)\n",
    "            all_features.append(features)\n",
    "    return all_labels, all_predicted_labels, all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83625c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(path_test)\n",
    "\n",
    "for filename in tqdm(filenames):\n",
    "    \n",
    "    filename = filename[:-4]\n",
    "    new_filename = filename.replace('_','')\n",
    "    \n",
    "    dataset_test = CustomImageDataset(path_image = 'patches/' + filename)   \n",
    "    loader_test = DataLoader(\n",
    "        batch_size = bs,\n",
    "        dataset=dataset_test,\n",
    "        num_workers = 16,\n",
    "        shuffle=False)\n",
    "\n",
    "    dataloaders = {'test':loader_test}\n",
    "    \n",
    "    _, predictions, all_features = evaluate(mc_model,dataloaders['test'])\n",
    "    \n",
    "    predictions_new = np.concatenate(predictions,axis = 1)\n",
    "    all_features_new = np.concatenate(all_features)\n",
    "    \n",
    "    path_patches = 'patches/'+ filename\n",
    "    path_predictions = 'patchesprediction/' + new_filename \n",
    "    path_predictions_features = 'features_predictions/' + filename + '/'\n",
    "    path_mask= '/home/ahabis/Scribble Project/truemasks/' + new_filename + '/'\n",
    "    mask_png = os.path.join(path_mask,os.listdir(path_mask)[0])\n",
    "    path_big_image = '/home/ahabis/sshfs/CAMELYON/test/images/'+ filename + '.tif'\n",
    "\n",
    "    \n",
    "    np.save(os.path.join(path_predictions_features, 'predictions.npy'), predictions_new)\n",
    "    np.save(os.path.join(path_predictions_features, 'features.npy'), all_features_new)\n",
    "    \n",
    "    \n",
    "    img = np.asarray(Image.open(mask_png))\n",
    "    \n",
    "    true_vals = []\n",
    "    for filename in os.listdir(path_patches):\n",
    "        split = filename.split('_')\n",
    "        y = int(split[2])\n",
    "        x = int(split[3].split('.')[0])\n",
    "        patch = img[x:x+512,y:y+512].flatten()\n",
    "        sum_ = np.sum(patch)/(512 * 512)\n",
    "        th = 0.5\n",
    "        if sum_>th:\n",
    "            print('hey')\n",
    "            true_vals.append(1)\n",
    "        else: \n",
    "            true_vals.append(0)\n",
    "    true_vals = np.array(true_vals)\n",
    "    np.save(os.path.join(path_predictions_features,'trues.npy'), true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8f5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
